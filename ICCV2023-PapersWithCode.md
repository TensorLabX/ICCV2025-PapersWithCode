

# ICCV2023-Papers-with-Code

### ã€ğŸ“£ ICCV 2023å½•ç”¨è®ºæ–‡åˆ—è¡¨å‘å¸ƒäº†ï¼ã€‘

![](ICCV2023.png)



> æ³¨0ï¼šæ¬¢è¿å„ä½åŒå­¦Starï¼Œåˆ†äº«ICCV-2023çš„Paperå’ŒCodeï¼
>
> æ³¨1ï¼šå†å¹´ICCVè®ºæ–‡æ±‡æ€»ï¼Œè¯¦è§ï¼š https://github.com/TensorLabX/ICCV2025-PapersWithCode
>

***

æ¬¢è¿æ‰«ç å…³æ³¨å…¬ä¼—å·ã€**Tensorå®éªŒå®¤**ã€‘ï¼Œè·å–æœ€æ–°**å¤§æ¨¡å‹ã€å…·èº«æ™ºèƒ½ã€CVã€æ‰©æ•£æ¨¡å‹ã€å¤šæ¨¡æ€ã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å½±åƒã€AIGCã€é¥æ„Ÿç­‰æ–¹å‘çš„è®ºæ–‡è§£è¯»ã€å‘å±•è¶‹åŠ¿å’Œå­¦ä¹ èµ„æ–™**ï¼Œèµ¶å¿«åŠ å…¥ä¸€èµ·å­¦ä¹ å§ï¼

![](TensorLab.jpg)

## AIå‚ç›´æ–¹å‘äº¤æµç¾¤å’Œè®ºæ–‡æŠ•ç¨¿ç¾¤å·²æˆç«‹ï¼

## ğŸ‘¨â€ğŸ”§ğŸ‘©â€ğŸ”§ğŸ‘¨â€ğŸ”¬ğŸ‘©â€ğŸ”¬ğŸ‘¨â€ğŸš€ğŸ‘¨â€ğŸš’ğŸ•µï¸â€: æ¬¢è¿è¿›ç¾¤ | Welcome


ç›®å‰å·²ç»å¼€è®¾çš„AIç»†åˆ†å‚ç›´æ–¹å‘äº¤æµç¾¤åŒ…æ‹¬ä½†ä¸é™äºï¼š**å¤§æ¨¡å‹ã€å¤šæ¨¡æ€ã€å…·èº«æ™ºèƒ½ã€CVã€æ‰©æ•£æ¨¡å‹ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²ã€ç›®æ ‡è·Ÿè¸ªã€åŒ»å­¦å½±åƒã€é¥æ„Ÿã€3DGSã€Mambaã€NeRFã€Transformerã€GANã€å¼‚å¸¸æ£€æµ‹/ç¼ºé™·æ£€æµ‹ã€SLAMã€äººè„¸æ£€æµ‹&è¯†åˆ«ã€OCRã€NASã€Re-IDã€è¶…åˆ†è¾¨ç‡ã€å¼ºåŒ–å­¦ä¹ ã€3Dé‡å»ºã€å§¿æ€ä¼°è®¡ã€è‡ªåŠ¨é©¾é©¶ã€æ´»ä½“æ£€æµ‹ã€æ·±åº¦ä¼°è®¡ã€å»å™ªã€æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ã€è½¦é“çº¿æ£€æµ‹ã€æ¨¡å‹å‰ªæ&å‹ç¼©ã€å»é›¾ã€å»é›¨ã€è¡Œä¸ºè¯†åˆ«ã€è§†é¢‘ç†è§£ã€å›¾åƒèåˆã€å›¾åƒæ£€ç´¢ç­‰**ã€‚

å¯ä»¥æ·»åŠ å¾®ä¿¡å°åŠ©æ‰‹å¾®ä¿¡ï¼š**Tensor333**æˆ–**Tensor555**ï¼Œè¯·å¤‡æ³¨ï¼š**ç ”ç©¶æ–¹å‘+åœ°åŒº+å­¦æ ¡/å…¬å¸åç§°+æ˜µç§°**ï¼å¦‚ï¼š**å¤§æ¨¡å‹+åŒ—äº¬+åŒ—èˆª+å°åŒ—**ï¼›ä¸€å®šè¦æ ¹æ®æ ¼å¼ç”³è¯·ï¼Œå¯ä»¥æ‹‰ä½ è¿›å¯¹åº”çš„äº¤æµç¾¤ã€‚

**å¦‚æœç›®å‰æ–¹å‘æœªå®šçš„çš„åŒå­¦ï¼Œå¯ä»¥å…ˆåŠ å…¥å¤§ç¾¤ï¼ˆå¤§ç¾¤å’Œå‚ç›´æ–¹å‘ç¾¤å¯ä»¥åŒæ—¶åŠ å…¥ï¼‰**ã€‚å¯ä»¥æ·»åŠ å¾®ä¿¡å°åŠ©æ‰‹å¾®ä¿¡ï¼š**Tensor333**æˆ–**Tensor555**ï¼Œè¯·å¤‡æ³¨ï¼š**æ–¹å‘æœªå®š+åœ°åŒº+å­¦æ ¡/å…¬å¸åç§°+æ˜µç§°**ï¼å¦‚ï¼š**æ–¹å‘æœªå®š+åŒ—äº¬+åŒ—èˆª+å°åŒ—**ï¼›

***
**å¦‚æœæƒ³è¿›é¡¶åˆŠé¡¶ä¼šè®ºæ–‡æŠ•ç¨¿å’Œäº¤æµç¾¤çš„åŒå­¦ã€‚**å¯ä»¥æ·»åŠ å¾®ä¿¡å°åŠ©æ‰‹å¾®ä¿¡ï¼š**Tensor333**æˆ–**Tensor555**ï¼Œè¯·å¤‡æ³¨ï¼š**é¡¶åˆŠé¡¶ä¼šåç§°+åœ°åŒº+å­¦æ ¡/å…¬å¸åç§°+æ˜µç§°**ï¼å¦‚ï¼š**CVPR+åŒ—äº¬+åŒ—èˆª+å°åŒ—**ï¼›
***


## ğŸ“™: **ã€è®ºæ–‡ç›®å½•ã€‘**

# ã€ICCV 2023 è®ºæ–‡å¼€æºç›®å½•ã€‘

- [Backbone](#Backbone)
- [CLIP](#CLIP)
- [MAE](#MAE)
- [GAN](#GAN)
- [GNN](#GNN)
- [MLP](#MLP)
- [NAS](#NAS)
- [OCR](#OCR)
- [NeRF](#NeRF)
- [DETR](#DETR)
- [Prompt](#Prompt)
- [Diffusion Models(æ‰©æ•£æ¨¡å‹)](#Diffusion)
- [Prompt](#Prompt)
- [Avatars](#Avatars)
- [ReID(é‡è¯†åˆ«)](#ReID)
- [é•¿å°¾åˆ†å¸ƒ(Long-Tail)](#Long-Tail)
- [Vision Transformer](#Vision-Transformer)
- [è§†è§‰å’Œè¯­è¨€(Vision-Language)](#VL)
- [è‡ªç›‘ç£å­¦ä¹ (Self-supervised Learning)](#SSL)
- [æ•°æ®å¢å¼º(Data Augmentation)](#DA)
- [ç›®æ ‡æ£€æµ‹(Object Detection)](#Object-Detection)
- [ç›®æ ‡è·Ÿè¸ª(Visual Tracking)](#VT)
- [è¯­ä¹‰åˆ†å‰²(Semantic Segmentation)](#Semantic-Segmentation)
- [å®ä¾‹åˆ†å‰²(Instance Segmentation)](#Instance-Segmentation)
- [å…¨æ™¯åˆ†å‰²(Panoptic Segmentation)](#Panoptic-Segmentation)
- [åŒ»å­¦å›¾åƒåˆ†ç±»(Medical Image Classfication)](#MIC)
- [åŒ»å­¦å›¾åƒåˆ†å‰²(Medical Image Segmentation)](#MIS)
- [è§†é¢‘ç›®æ ‡åˆ†å‰²(Video Object Segmentation)](#VOS)
- [è§†é¢‘å®ä¾‹åˆ†å‰²(Video Instance Segmentation)](#VIS)
- [å‚è€ƒå›¾åƒåˆ†å‰²(Referring Image Segmentation)](#RIS)
- [å›¾åƒæŠ å›¾(Image Matting)](#Matting)
- [Low-level Vision](#LLV)
- [è¶…åˆ†è¾¨ç‡(Super-Resolution)](#SR)
- [å»å™ª(Denoising)](#Denoising)
- [å»æ¨¡ç³Š(Deblur)](#Deblur)
- [3Dç‚¹äº‘(3D Point Cloud)](#3D-Point-Cloud)
- [3Dç›®æ ‡æ£€æµ‹(3D Object Detection)](#3DOD)
- [3Dè¯­ä¹‰åˆ†å‰²(3D Semantic Segmentation)](#3DSS)
- [3Dç›®æ ‡è·Ÿè¸ª(3D Object Tracking)](#3D-Object-Tracking)
- [3Dè¯­ä¹‰åœºæ™¯è¡¥å…¨(3D Semantic Scene Completion)](#3DSSC)
- [3Dé…å‡†(3D Registration)](#3D-Registration)
- [3Däººä½“å§¿æ€ä¼°è®¡(3D Human Pose Estimation)](#3D-Human-Pose-Estimation)
- [3Däººä½“Meshä¼°è®¡(3D Human Mesh Estimation)](#3D-Human-Pose-Estimation)
- [åŒ»å­¦å›¾åƒ(Medical Image)](#Medical-Image)
- [å›¾åƒç”Ÿæˆ(Image Generation)](#Image-Generation)
- [è§†é¢‘ç”Ÿæˆ(Video Generation)](#Video-Generation)
- [å›¾åƒç¼–è¾‘(Image Editing)](#Image-Editing)
- [è§†é¢‘ç¼–è¾‘(Video Editing)](#Video-Editing)
- [è§†é¢‘ç†è§£(Video Understanding)](#Video-Understanding)
- [äººä½“è¿åŠ¨ç”Ÿæˆ(Human Motion Generation)](#Human-Motion-Generation)
- [ä½å…‰ç…§å›¾åƒå¢å¼º(Low-light Image Enhancement)](#Low-light-Image-Enhancement)
- [åœºæ™¯æ–‡æœ¬è¯†åˆ«(Scene Text Recognition)](#STR)
- [å›¾åƒæ£€ç´¢(Image Retrieval)](#Image-Retrieval)
- [å›¾åƒèåˆ(Image Fusion)](#Image-Fusion)
- [è½¨è¿¹é¢„æµ‹(Trajectory Prediction) ](#Trajectory-Prediction)
- [äººç¾¤è®¡æ•°(Crowd Counting)](#Crowd-Counting)
- [Video Quality Assessment(è§†é¢‘è´¨é‡è¯„ä»·)](#Video-Quality-Assessment)
- [å…¶å®ƒ(Others)](#Others)

<a name="Avatars"></a>

# Avatars 

**Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control**

Paper: https://arxiv.org/abs/2303.17606

Code: https://github.com/songrise/AvatarCraft

<a name="Backbone"></a>

# Backbone

**Rethinking Mobile Block for Efficient Attention-based Models**

- Paper: https://arxiv.org/abs/2301.01146
- Code: https://github.com/zhangzjn/EMO 

<a name="CLIP"></a>

# CLIP

**PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization**

- Paper: https://arxiv.org/abs/2307.15199
- Code: [https://PromptStyler.github.io/](https://promptstyler.github.io/)

**CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for Multimodal Machine Translation**

- Paper: https://arxiv.org/abs/2308.15226
- Code: http://www.github.com/devaansh100/CLIPTrans

<a name="NeRF"></a>

# NeRF

**IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable Novel View Synthesis**

- Homepage: https://zju3dv.github.io/intrinsic_nerf/
- Paper: https://arxiv.org/abs/2210.00647
- Code: https://github.com/zju3dv/IntrinsicNeRF

**Transforming Text into Neural Human Avatars with Parameterized Shape and Pose Control**

- Paper: https://arxiv.org/abs/2303.17606

- Code: https://github.com/songrise/AvatarCraft

**FlipNeRF: Flipped Reflection Rays for Few-shot Novel View Synthesis**

- Homepage: https://shawn615.github.io/flipnerf/
- Code: https://github.com/shawn615/FlipNeRF
- Paper: https://arxiv.org/abs/2306.17723

**Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural Radiance Fields**

- Homepage: https://wbhu.github.io/projects/Tri-MipRF

- Paper: https://arxiv.org/abs/2307.11335
- Code: https://github.com/wbhu/Tri-MipRF

<a name="Diffusion"></a>

# Diffusion Models(æ‰©æ•£æ¨¡å‹)

**PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle Adjustment**

- Paper: https://arxiv.org/abs/2306.15667
- Code: https://github.com/facebookresearch/PoseDiffusion

**FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model**

- Paper: https://arxiv.org/abs/2303.09833
- Code: https://github.com/vvictoryuki/FreeDoM

**BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion**

- Paper: https://arxiv.org/abs/2307.10816
- Code: https://github.com/Sierkinhane/BoxDiff

**BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction**

- Paper: https://arxiv.org/abs/2211.14304
- Code: https://github.com/BarqueroGerman/BeLFusion

**DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion**

- Paper: https://arxiv.org/abs/2303.06840
- Code: https://github.com/Zhaozixiang1228/MMIF-DDFM

**DIRE for Diffusion-Generated Image Detection**

- Paper: https://arxiv.org/abs/2303.09295
- Code: https://github.com/ZhendongWang6/DIRE

<a name="Prompt"></a>

# Prompt

**Read-only Prompt Optimization for Vision-Language Few-shot Learning** 

- Paper: https://arxiv.org/abs/2308.14960
- Code: https://github.com/mlvlab/RPO

**Introducing Language Guidance in Prompt-based Continual Learning**

- Paper: https://arxiv.org/abs/2308.15827
- Code: None

<a name="VL"></a>

# è§†è§‰å’Œè¯­è¨€(Vision-Language)

**Read-only Prompt Optimization for Vision-Language Few-shot Learning** 

- Paper: https://arxiv.org/abs/2308.14960
- Code: https://github.com/mlvlab/RPO

<a name="Object-Detection"></a>

# ç›®æ ‡æ£€æµ‹(Object Detection)

**Femtodet: an object detection baseline for energy versus performance tradeoffs**

- Paper: https://arxiv.org/abs/2301.06719
- Code: https://github.com/yh-pengtu/FemtoDet

**Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment**

- Paper: https://arxiv.org/abs/2207.13085
- Code: https://github.com/Atten4Vis/GroupDETR

**Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection**

- Paper: https://arxiv.org/abs/2205.09613
- Code: https://github.com/LiewFeng/imTED

**ASAG: Building Strong One-Decoder-Layer Sparse Detectors via Adaptive Sparse Anchor Generation**

- Paper: https://arxiv.org/abs/2308.09242
- Code: https://github.com/iSEE-Laboratory/ASAG

<a name="VT"></a>

# ç›®æ ‡è·Ÿè¸ª(Visual Tracking)

**Cross-modal Orthogonal High-rank Augmentation for RGB-Event Transformer-trackers**

- Paper: https://arxiv.org/abs/2307.04129
- Code: https://github.com/ZHU-Zhiyu/High-Rank_RGB-Event_Tracker 

<a name="Semantic-Segmentation"></a>

# è¯­ä¹‰åˆ†å‰²(Semantic Segmentation)

**Segment Anything**

- Homepage: https://segment-anything.com/
- Paper: https://arxiv.org/abs/2304.02643
- Code: https://github.com/facebookresearch/segment-anything

**MARS: Model-agnostic Biased Object Removal without Additional Supervision for Weakly-Supervised Semantic Segmentation**

- Paper: https://arxiv.org/abs/2304.09913
- Code: https://github.com/shjo-april/MARS

**FreeCOS: Self-Supervised Learning from Fractals and Unlabeled Images for Curvilinear Object Segmentation**

- Paper: https://arxiv.org/abs/2307.07245
- Code: https://github.com/TY-Shi/FreeCOS

**Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection in Semantic Segmentation**

- Paper: https://arxiv.org/abs/2211.14512
- Code: https://github.com/yyliu01

**Disentangle then Parse:Night-time Semantic Segmentation with Illumination Disentanglement**

- Paper: https://arxiv.org/abs/2307.09362
- Code: https://github.com/w1oves/DTP

<a name="VOS"></a>

# è§†é¢‘ç›®æ ‡åˆ†å‰²(Video Object Segmentation)

**Towards Robust Referring Video Object Segmentation with Cyclic Relational Consensus**

- Paper: https://arxiv.org/abs/2207.01203 

- Code: https://github.com/lxa9867/R2VOS

<a name="VIS"></a>

# è§†é¢‘å®ä¾‹åˆ†å‰²(Video Instance Segmentation)

**DVIS: Decoupled Video Instance Segmentation Framework**

- Paper: https://arxiv.org/abs/2306.03413
- Code: https://github.com/zhang-tao-whu/DVIS

<a name="MIC"></a>

# åŒ»å­¦å›¾åƒåˆ†ç±»

**BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification**

- Paper: https://arxiv.org/abs/2203.01937

- Code: https://github.com/cyh-0/BoMD

<a name="MIS"></a>

# åŒ»å­¦å›¾åƒåˆ†å‰²

**CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection**

- Paper: https://arxiv.org/abs/2301.00785
- Code: https://github.com/ljwztc/CLIP-Driven-Universal-Model

<a name="LLV"></a>

# Low-level Vision

**Self-supervised Learning to Bring Dual Reversed Rolling Shutter Images Alive**

- Paper: https://arxiv.org/abs/2305.19862
- Code: https://github.com/shangwei5/SelfDRSC 

<a name="SR"></a>

# è¶…åˆ†è¾¨ç‡(Super-Resolution)

**Spherical Space Feature Decomposition for Guided Depth Map Super-Resolution.**

- Paper: https://arxiv.org/abs/2303.08942
- Code: https://github.com/Zhaozixiang1228/GDSR-SSDNet 

<a name="3D-Point-Cloud"></a>

# 3Dç‚¹äº‘(3D Point Cloud)

**Robo3D: Towards Robust and Reliable 3D Perception against Corruptions**

- Homepage: https://ldkong.com/Robo3D
- Paper: https://arxiv.org/abs/2303.17597
- Code: https://github.com/ldkong1205/Robo3D

**Instance-aware Dynamic Prompt Tuning for Pre-trained Point Cloud Models**

- Paper: https://arxiv.org/abs/2304.07221
- Code: https://github.com/zyh16143998882/ICCV23-IDPT

**Point Contrastive Prediction with Semantic Clustering for Self-Supervised Learning on Point Cloud Videos**

- Paper: https://arxiv.org/abs/2308.09247
- Code: None

<a name="3DOD"></a>

# 3Dç›®æ ‡æ£€æµ‹(3D Object Detection)

**PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images**

- Paper: https://arxiv.org/abs/2206.01256
- Code: https://github.com/megvii-research/PETR

**DQS3D: Densely-matched Quantization-aware Semi-supervised 3D Detection**

- Paper: https://arxiv.org/abs/2304.13031
- Code: https://github.com/AIR-DISCOVER/DQS3D

**SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection**

- Paper: https://arxiv.org/abs/2304.14340
- Code: https://github.com/yichen928/SparseFusion

**StreamPETR: Exploring Object-Centric Temporal Modeling for Efficient Multi-View 3D Object Detection**

- Paper: https://arxiv.org/abs/2303.11926
- Code: https://github.com/exiawsh/StreamPETR.git

**Cross Modal Transformer: Towards Fast and Robust 3D Object Detection**

- Paper: https://arxiv.org/abs/2301.01283
- Code: https://github.com/junjie18/CMT.git

**MetaBEV: Solving Sensor Failures for BEV Detection and Map Segmentation**

- Paper: https://arxiv.org/abs/2304.09801
- Project: https://chongjiange.github.io/metabev.html
- Code: https://github.com/ChongjianGE/MetaBEV

**Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling**

- Paper: https://arxiv.org/abs/2307.07944
- Code: https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet

**SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-view 3D Object Detection**

- Paper: https://arxiv.org/abs/2307.11477
- Code: https://github.com/mengtan00/SA-BEV

<a name="3DSS"></a>

# 3Dè¯­ä¹‰åˆ†å‰²(3D Semantic Segmentation)

**Rethinking Range View Representation for LiDAR Segmentation**

- Homepage: https://ldkong.com/RangeFormer
- Paper: https://arxiv.org/abs/2303.05367
- Code: None

<a name="3D-Object-Tracking"></a>

# 3Dç›®æ ‡è·Ÿè¸ª(3D Object Tracking)

**MBPTrack: Improving 3D Point Cloud Tracking with Memory Networks and Box Priors**

- Paper: https://arxiv.org/abs/2303.05071
- Code : https://github.com/slothfulxtx/MBPTrack3D

<a name="Video-Understanding"></a>

# è§†é¢‘ç†è§£(Video Understanding)

**Unmasked Teacher: Towards Training-Efficient Video Foundation Models**

- Paper: https://arxiv.org/abs/2303.16058

- Code: https://github.com/OpenGVLab/unmasked_teacher

<a name="Image-Generation"></a>

# å›¾åƒç”Ÿæˆ(Image Generation)

**FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model**

- Paper: https://arxiv.org/abs/2303.09833
- Code: https://github.com/vvictoryuki/FreeDoM

**BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion**

- Paper: https://arxiv.org/abs/2307.10816
- Code: https://github.com/Sierkinhane/BoxDiff 

<a name="Video-Generation"></a>

# è§†é¢‘ç”Ÿæˆ(Video Generation)

**Simulating Fluids in Real-World Still Images**

- Homepage: https://slr-sfs.github.io/ 
- Paper: https://arxiv.org/abs/2204.11335
- Code: https://github.com/simon3dv/SLR-SFS

<a name="Image-Editing"></a>

# å›¾åƒç¼–è¾‘(Image Editing)

**Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing**

- Paper: https://arxiv.org/abs/2304.02051
- Code: https://github.com/aimagelab/multimodal-garment-designer 

<a name="Video-Editing"></a>

# è§†é¢‘ç¼–è¾‘(Video Editing)

**FateZero: Fusing Attentions for Zero-shot Text-based Video Editing**

- Project: https://fate-zero-edit.github.io/ 
- Paper: https://arxiv.org/abs/2303.09535
- Code: https://github.com/ChenyangQiQi/FateZero 

<a name="Human-Motion-Generation"></a>

# äººä½“è¿åŠ¨ç”Ÿæˆ(Human Motion Generation)

**BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction**

- Paper: https://arxiv.org/abs/2211.14304
- Code: https://github.com/BarqueroGerman/BeLFusion 

<a name="Low-light-Image-Enhancement"></a>

# ä½å…‰ç…§å›¾åƒå¢å¼º(Low-light Image Enhancement)

**Implicit Neural Representation for Cooperative Low-light Image Enhancement**

- Paper: https://arxiv.org/abs/2303.11722
- Code: https://github.com/Ysz2022/NeRCo

<a name="STD"></a>

# åœºæ™¯æ–‡æœ¬æ£€æµ‹(Scene Text Detection)



<a name="STR"></a>

# åœºæ™¯æ–‡æœ¬è¯†åˆ«(Scene Text Recognition)

**Self-supervised Character-to-Character Distillation for Text Recognition**

- Paper: https://arxiv.org/abs/2211.00288
- Code: https://github.com/TongkunGuan/CCD

**MRN: Multiplexed Routing Network for Incremental Multilingual Text Recognition**

- Paper: https://arxiv.org/abs/2305.14758
- Code: https://github.com/simplify23/MRN
- ä¸­æ–‡è§£è¯»ï¼šhttps://zhuanlan.zhihu.com/p/643948935 

<a name="Image-Retrieval"></a>

# å›¾åƒæ£€ç´¢(Image Retrieval)

**Zero-Shot Composed Image Retrieval with Textual Inversion**

- Paper: https://arxiv.org/abs/2303.15247
- Code: https://github.com/miccunifi/SEARLE 

<a name="Image-Fusion"></a>

# å›¾åƒèåˆ(Image Fusion)

**DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion**

- Paper: https://arxiv.org/abs/2303.06840
- Code: https://github.com/Zhaozixiang1228/MMIF-DDFM

<a name="Trajectory-Prediction"></a>

# è½¨è¿¹é¢„æµ‹(Trajectory Prediction)

**EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting**

- Homepage: https://inhwanbae.github.io/publication/eigentrajectory/

- Paper: https://arxiv.org/abs/2307.09306 
- Code: https://github.com/InhwanBae/EigenTrajectory

<a name="Crowd-Counting"></a>

# äººç¾¤è®¡æ•°(Crowd Counting)

**Point-Query Quadtree for Crowd Counting, Localization, and More**

- Paper: https://arxiv.org/abs/2308.13814
- Code: https://github.com/cxliu0/PET

<a name="Video-Quality-Assessment"></a>

# Video Quality Assessment(è§†é¢‘è´¨é‡è¯„ä»·)

**Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives**

- Paper: https://arxiv.org/abs/2211.04894
- Code: https://github.com/VQAssessment/DOVER

<a name="Others"></a>

# å…¶å®ƒ(Others)

**MotionBERT: A Unified Perspective on Learning Human Motion Representations**

- Homepage: https://motionbert.github.io/
- Paper: https://arxiv.org/abs/2210.06551
- Code: https://github.com/Walter0807/MotionBERT 

**Graph Matching with Bi-level Noisy Correspondence**

- Paper: https://arxiv.org/pdf/2212.04085.pdf
- Code: https://github.com/Lin-Yijie/Graph-Matching-Networks/tree/main/COMMON 

**LDL: Line Distance Functions for Panoramic Localization**

- Paper: https://arxiv.org/abs/2308.13989
- Code: https://github.com/82magnolia/panoramic-localization

**Active Neural Mapping**

- Homepage: https://zikeyan.github.io/active-INR/index.html
- Paper: https://arxiv.org/abs/2308.16246
- Code: https://zikeyan.github.io/active-INR/index.html#

**Reconstructing Groups of People with Hypergraph Relational Reasoning**

- Paper: https://arxiv.org/abs/2308.15844
- Code: https://github.com/boycehbz/GroupRec