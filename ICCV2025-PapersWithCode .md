# ICCV2025-Papers-with-Code
![](ICCV2025.png)



> æ³¨0ï¼šæ¬¢è¿å„ä½åŒå­¦Starï¼Œåˆ†äº«ICCV-2025çš„Paperå’ŒCodeï¼
>
> æ³¨1ï¼šå†å¹´ICCVè®ºæ–‡æ±‡æ€»ï¼Œè¯¦è§ï¼š https://github.com/TensorLabX/ICCV2025-PapersWithCode
>

***

æ¬¢è¿æ‰«ç å…³æ³¨å…¬ä¼—å·ã€**Tensorå®éªŒå®¤**ã€‘ï¼Œè·å–æœ€æ–°**å¤§æ¨¡å‹ã€å…·èº«æ™ºèƒ½ã€CVã€æ‰©æ•£æ¨¡å‹ã€å¤šæ¨¡æ€ã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å½±åƒã€AIGCã€é¥æ„Ÿç­‰æ–¹å‘çš„è®ºæ–‡è§£è¯»ã€å‘å±•è¶‹åŠ¿å’Œå­¦ä¹ èµ„æ–™**ï¼Œèµ¶å¿«åŠ å…¥ä¸€èµ·å­¦ä¹ å§ï¼

![](TensorLab.jpg)

## AIå‚ç›´æ–¹å‘äº¤æµç¾¤å’Œè®ºæ–‡æŠ•ç¨¿ç¾¤å·²æˆç«‹ï¼

## ğŸ‘¨â€ğŸ”§ğŸ‘©â€ğŸ”§ğŸ‘¨â€ğŸ”¬ğŸ‘©â€ğŸ”¬ğŸ‘¨â€ğŸš€ğŸ‘¨â€ğŸš’ğŸ•µï¸â€: æ¬¢è¿è¿›ç¾¤ | Welcome


ç›®å‰å·²ç»å¼€è®¾çš„AIç»†åˆ†å‚ç›´æ–¹å‘äº¤æµç¾¤åŒ…æ‹¬ä½†ä¸é™äºï¼š**å¤§æ¨¡å‹ã€å¤šæ¨¡æ€ã€å…·èº«æ™ºèƒ½ã€CVã€æ‰©æ•£æ¨¡å‹ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²ã€ç›®æ ‡è·Ÿè¸ªã€åŒ»å­¦å½±åƒã€é¥æ„Ÿã€3DGSã€Mambaã€NeRFã€Transformerã€GANã€å¼‚å¸¸æ£€æµ‹/ç¼ºé™·æ£€æµ‹ã€SLAMã€äººè„¸æ£€æµ‹&è¯†åˆ«ã€OCRã€NASã€Re-IDã€è¶…åˆ†è¾¨ç‡ã€å¼ºåŒ–å­¦ä¹ ã€3Dé‡å»ºã€å§¿æ€ä¼°è®¡ã€è‡ªåŠ¨é©¾é©¶ã€æ´»ä½“æ£€æµ‹ã€æ·±åº¦ä¼°è®¡ã€å»å™ªã€æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ã€è½¦é“çº¿æ£€æµ‹ã€æ¨¡å‹å‰ªæ&å‹ç¼©ã€å»é›¾ã€å»é›¨ã€è¡Œä¸ºè¯†åˆ«ã€è§†é¢‘ç†è§£ã€å›¾åƒèåˆã€å›¾åƒæ£€ç´¢ç­‰**ã€‚

å¯ä»¥æ·»åŠ å¾®ä¿¡å°åŠ©æ‰‹å¾®ä¿¡ï¼š**Tensor333**æˆ–**Tensor555**ï¼Œè¯·å¤‡æ³¨ï¼š**ç ”ç©¶æ–¹å‘+åœ°åŒº+å­¦æ ¡/å…¬å¸åç§°+æ˜µç§°**ï¼å¦‚ï¼š**å¤§æ¨¡å‹+åŒ—äº¬+åŒ—èˆª+å°åŒ—**ï¼›ä¸€å®šè¦æ ¹æ®æ ¼å¼ç”³è¯·ï¼Œå¯ä»¥æ‹‰ä½ è¿›å¯¹åº”çš„äº¤æµç¾¤ã€‚

**å¦‚æœç›®å‰æ–¹å‘æœªå®šçš„çš„åŒå­¦ï¼Œå¯ä»¥å…ˆåŠ å…¥å¤§ç¾¤ï¼ˆå¤§ç¾¤å’Œå‚ç›´æ–¹å‘ç¾¤å¯ä»¥åŒæ—¶åŠ å…¥ï¼‰**ã€‚å¯ä»¥æ·»åŠ å¾®ä¿¡å°åŠ©æ‰‹å¾®ä¿¡ï¼š**Tensor333**æˆ–**Tensor555**ï¼Œè¯·å¤‡æ³¨ï¼š**æ–¹å‘æœªå®š+åœ°åŒº+å­¦æ ¡/å…¬å¸åç§°+æ˜µç§°**ï¼å¦‚ï¼š**æ–¹å‘æœªå®š+åŒ—äº¬+åŒ—èˆª+å°åŒ—**ï¼›

***
**å¦‚æœæƒ³è¿›é¡¶åˆŠé¡¶ä¼šè®ºæ–‡æŠ•ç¨¿å’Œäº¤æµç¾¤çš„åŒå­¦ã€‚**å¯ä»¥æ·»åŠ å¾®ä¿¡å°åŠ©æ‰‹å¾®ä¿¡ï¼š**Tensor333**æˆ–**Tensor555**ï¼Œè¯·å¤‡æ³¨ï¼š**é¡¶åˆŠé¡¶ä¼šåç§°+åœ°åŒº+å­¦æ ¡/å…¬å¸åç§°+æ˜µç§°**ï¼å¦‚ï¼š**CVPR+åŒ—äº¬+åŒ—èˆª+å°åŒ—**ï¼›
***


## ğŸ“™: **ã€è®ºæ–‡ç›®å½•ã€‘**

# ã€ICCV 2025 è®ºæ–‡å¼€æºç›®å½•ã€‘
- [Agent](#Agent)
- [Avatars](#Avatars)
- [Backbone](#Backbone)
- [CLIP](#CLIP)
- [Diffusion Models(æ‰©æ•£æ¨¡å‹)](#Diffusion)
- [Embodied AI](#Embodied-AI)
- [MAE](#MAE)
- [Mamba](#Mamba)
- [GAN](#GAN)
- [GNN](#GNN)
- [MLP](#MLP)
- [NAS](#NAS)
- [OCR](#OCR)
- [NeRF](#NeRF)
- [DETR](#DETR)
- [Prompt](#Prompt)
- [ReID(é‡è¯†åˆ«)](#ReID)
- [é•¿å°¾åˆ†å¸ƒ(Long-Tail)](#Long-Tail)
- [å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)](#MLLM)
- [å¤§è¯­è¨€æ¨¡å‹(LLM)](#LLM)
- [ä¸–ç•Œæ¨¡å‹(World Model)](#WM)
- [Vision Transformer](#Vision-Transformer)
- [è§†è§‰å’Œè¯­è¨€(Vision-Language)](#VL)
- [è‡ªç›‘ç£å­¦ä¹ (Self-supervised Learning)](#SSL)
- [æ•°æ®å¢å¼º(Data Augmentation)](#DA)
- [ç›®æ ‡æ£€æµ‹(Object Detection)](#Object-Detection)
- [ç›®æ ‡è·Ÿè¸ª(Visual Tracking)](#VT)
- [è¯­ä¹‰åˆ†å‰²(Semantic Segmentation)](#Semantic-Segmentation)
- [å®ä¾‹åˆ†å‰²(Instance Segmentation)](#Instance-Segmentation)
- [å…¨æ™¯åˆ†å‰²(Panoptic Segmentation)](#Panoptic-Segmentation)
- [åŒ»å­¦å›¾åƒåˆ†ç±»(Medical Image Classfication)](#MIC)
- [åŒ»å­¦å›¾åƒåˆ†å‰²(Medical Image Segmentation)](#MIS)
- [è§†é¢‘ç›®æ ‡åˆ†å‰²(Video Object Segmentation)](#VOS)
- [è§†é¢‘å®ä¾‹åˆ†å‰²(Video Instance Segmentation)](#VIS)
- [å‚è€ƒå›¾åƒåˆ†å‰²(Referring Image Segmentation)](#RIS)
- [å›¾åƒæŠ å›¾(Image Matting)](#Matting)
- [Low-level Vision](#LLV)
- [è¶…åˆ†è¾¨ç‡(Super-Resolution)](#SR)
- [å»å™ª(Denoising)](#Denoising)
- [å»æ¨¡ç³Š(Deblur)](#Deblur)
- [3DGS(Gaussian Splatting)](#3DGS)
- [3Dç‚¹äº‘(3D Point Cloud)](#3D-Point-Cloud)
- [3Dç›®æ ‡æ£€æµ‹(3D Object Detection)](#3DOD)
- [3Dè¯­ä¹‰åˆ†å‰²(3D Semantic Segmentation)](#3DSS)
- [3Dç›®æ ‡è·Ÿè¸ª(3D Object Tracking)](#3D-Object-Tracking)
- [3Dè¯­ä¹‰åœºæ™¯è¡¥å…¨(3D Semantic Scene Completion)](#3DSSC)
- [3Dé…å‡†(3D Registration)](#3D-Registration)
- [3Däººä½“å§¿æ€ä¼°è®¡(3D Human Pose Estimation)](#3D-Human-Pose-Estimation)
- [3Däººä½“Meshä¼°è®¡(3D Human Mesh Estimation)](#3D-Human-Pose-Estimation)
- [åŒ»å­¦å›¾åƒ(Medical Image)](#Medical-Image)
- [å›¾åƒç”Ÿæˆ(Image Generation)](#Image-Generation)
- [è§†é¢‘ç”Ÿæˆ(Video Generation)](#Video-Generation)
- [å›¾åƒç¼–è¾‘(Image Editing)](#Image-Editing)
- [è§†é¢‘ç¼–è¾‘(Video Editing)](#Video-Editing)
- [è§†é¢‘ç†è§£(Video Understanding)](#Video-Understanding)
- [äººä½“è¿åŠ¨ç”Ÿæˆ(Human Motion Generation)](#Human-Motion-Generation)
- [ä½å…‰ç…§å›¾åƒå¢å¼º(Low-light Image Enhancement)](#Low-light-Image-Enhancement)
- [åœºæ™¯æ–‡æœ¬è¯†åˆ«(Scene Text Recognition)](#STR)
- [å›¾åƒæ£€ç´¢(Image Retrieval)](#Image-Retrieval)
- [å›¾åƒèåˆ(Image Fusion)](#Image-Fusion)
- [è½¨è¿¹é¢„æµ‹(Trajectory Prediction) ](#Trajectory-Prediction)
- [äººç¾¤è®¡æ•°(Crowd Counting)](#Crowd-Counting)
- [æ–‡æœ¬æ£€æµ‹(Text Detection)](#Text-Detection)
- [çŸ¥è¯†è’¸é¦(Knowledge Distillation)](#KD)
- [æ¨¡å‹å‰ªæ(Model Pruning)](#Pruning)
- [å›¾åƒå‹ç¼©(Image Compression)](#IC)
- [ä¸‰ç»´é‡å»º(3D Reconstruction)](#3D-Reconstruction)
- [æ·±åº¦ä¼°è®¡(Depth Estimation)](#Depth-Estimation)
- [è½¨è¿¹é¢„æµ‹(Trajectory Prediction)](#TP)
- [è½¦é“çº¿æ£€æµ‹(Lane Detection)](#Lane-Detection)
- [å›¾åƒæè¿°(Image Captioning)](#Image-Captioning)
- [è§†è§‰é—®ç­”(Visual Question Answering)](#VQA)
- [æ‰‹è¯­è¯†åˆ«(Sign Language Recognition)](#SLR)
- [è§†é¢‘é¢„æµ‹(Video Prediction)](#Video-Prediction)
- [æ–°è§†ç‚¹åˆæˆ(Novel View Synthesis)](#NVS)
- [Zero-Shot Learning(é›¶æ ·æœ¬å­¦ä¹ )](#ZSL)
- [ç«‹ä½“åŒ¹é…(Stereo Matching)](#Stereo-Matching)
- [ç‰¹å¾åŒ¹é…(Feature Matching)](#Feature-Matching)
- [æš—å…‰å›¾åƒå¢å¼º(Low-light Image Enhancement)](#Low-light)
- [åœºæ™¯å›¾ç”Ÿæˆ(Scene Graph Generation)](#SGG)
- [é£æ ¼è¿ç§»(Style Transfer)](#ST)
- [éšå¼ç¥ç»è¡¨ç¤º(Implicit Neural Representations)](#INR)
- [å›¾åƒè´¨é‡è¯„ä»·(Image Quality Assessment)](#IQA)
- [è§†é¢‘è´¨é‡è¯„ä»·(Video Quality Assessment)](#Video-Quality-Assessment)
- [å‹ç¼©æ„ŸçŸ¥(Compressive Sensing)](#CS)
- [æ•°æ®é›†(Datasets)](#Datasets)
- [æ–°ä»»åŠ¡(New Tasks)](#New-Tasks)
- [Video Quality Assessment(è§†é¢‘è´¨é‡è¯„ä»·)](#Video-Quality-Assessment)
- [å…¶å®ƒ(Others)](#Others)




<a name="Agent"></a>

# Agent





<a name="Avatars"></a>

# Avatars




# Backbone

**TinyViM: Frequency Decoupling for Tiny Hybrid Vision Mamba**

- Paper: https://arxiv.org/abs/2411.17473
- Code: https://github.com/xwmaxwma/TinyViM


<a name="CLIP"></a>

# CLIP



<a name="Mamba"></a>

# Mamba

**TinyViM: Frequency Decoupling for Tiny Hybrid Vision Mamba**

- Paper: https://arxiv.org/abs/2411.17473
- Code: https://github.com/xwmaxwma/TinyViM

**Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers**

- Projectï¼šhttps://tiger-ai-lab.github.io/Vamba/
- Paperï¼šhttps://arxiv.org/abs/2503.11579
- Codeï¼šhttps://github.com/TIGER-AI-Lab/Vamba



<a name="Embodied-AI"></a>

# Embodied AI




<a name="GAN"></a>

# GAN

<a name="OCR"></a>

# OCR


<a name="NeRF"></a>

# NeRF



<a name="DETR"></a>

# DETR




<a name="Prompt"></a>

# Prompt

<a name="MLLM"></a>

# å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)

**FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers**

- Paper: https://arxiv.org/abs/2501.16297
- Code: https://github.com/JiuTian-VL/JiuTian-FALCON
- Project: https://jiutian-vl.github.io/FALCON.github.io/


<a name="LLM"></a>

# å¤§è¯­è¨€æ¨¡å‹(LLM)




<a name="WM"></a>

# World Model(ä¸–ç•Œæ¨¡å‹)

**Medical World Model: Generative Simulation of Tumor Evolution for Treatment Planning**

- Project: https://yijun-yang.github.io/MeWM/
- Paper: https://arxiv.org/abs/2506.02327
- Code: https://github.com/scott-yjyang/MeWM


<a name="ReID"></a>

# ReID(é‡è¯†åˆ«)





<a name="Diffusion"></a>

# æ‰©æ•£æ¨¡å‹(Diffusion Models)

**Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction**
- Paper: https://arxiv.org/abs/2507.23021
- Codeï¼š https://github.com/aimagelab/ScanDiff
- Homeï¼šhttps://aimagelab.github.io/ScanDiff/



**From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers**

- Paper: https://arxiv.org/abs/2503.06923
- Code: https://github.com/Shenyi-Z/TaylorSeer


**Text Embedding Knows How to Quantize Text-Guided Diffusion Models**
- Paper: 
- Code: https://github.com/jimmy9704/QLIP


<a name="Vision-Transformer"></a>

# Vision Transformer



<a name="VL"></a>

# è§†è§‰å’Œè¯­è¨€(Vision-Language)




<a name="Object-Detection"></a>

# ç›®æ ‡æ£€æµ‹(Object Detection)




<a name="Anomaly-Detection"></a>

# å¼‚å¸¸æ£€æµ‹(Anomaly Detection)



<a name="VT"></a>

# ç›®æ ‡è·Ÿè¸ª(Object Tracking)




<a name="MI"></a>

# åŒ»å­¦å›¾åƒ(Medical Image)

**Medical World Model: Generative Simulation of Tumor Evolution for Treatment Planning**

- Project: https://yijun-yang.github.io/MeWM/
- Paper: https://arxiv.org/abs/2506.02327
- Code: https://github.com/scott-yjyang/MeWM




# åŒ»å­¦å›¾åƒåˆ†å‰²(Medical Image Segmentation)




<a name="Autonomous-Driving"></a>

# è‡ªåŠ¨é©¾é©¶(Autonomous Driving)

**Where, What, Why: Towards Explainable Driver Attention Prediction**

- Paper: https://arxiv.org/abs/2506.23088
- Code: https://github.com/yuchen2199/Explainable-Driver-Attention-Prediction
- Project: https://github.com/yuchen2199/Explainable-Driver-Attention-Prediction


**ROADWork Dataset: Learning to Recognize, Observe, Analyze and Drive Through Work Zones**

- Paper: https://arxiv.org/abs/2406.07661
- Code: https://github.com/anuragxel/roadwork-dataset
- Project: https://www.cs.cmu.edu/~ILIM/roadwork_dataset/

**DriveMM: All-in-One Large Multimodal Model for Autonomous Driving**

- Project: https://zhijian11.github.io/DriveMM/
- Paper: https://arxiv.org/abs/2412.07689
- Code: https://github.com/zhijian11/DriveMM


<a name="3DGS"></a>

# 3DGS(Gaussian Splatting)
**6DOPE-GS: Online 6D Object Pose Estimation using Gaussian Splatting**
- Paper: https://arxiv.org/pdf/2412.01543
- Code: 
- Home: https://pearl-robot-lab.github.io/6dope-gs/


**STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene**
- Paper: https://hyzhouboy.github.io/
- Code: 


# 3Dç‚¹äº‘(3D-Point-Cloud)




<a name="3DOD"></a>

# 3Dç›®æ ‡æ£€æµ‹(3D Object Detection)



<a name="3DOD"></a>

# 3Dè¯­ä¹‰åˆ†å‰²(3D Semantic Segmentation)

<a name="3DSSC"></a>
# 3Dè¯­ä¹‰åœºæ™¯è¡¥å…¨(3D Semantic Scene Completion)
**WonderPlay: Dynamic 3D Scene Generation from a Single Image and Actions**
- Paper: https://arxiv.org/abs/2505.18151
- Code:
- Home: https://kyleleey.github.io/WonderPlay/

<a name="LLV"></a>

# Low-level Vision


**EAMamba: Efficient All-Around Vision State Space Model for Image Restoration**

- Paper: https://arxiv.org/abs/2506.22246
- Code: https://github.com/daidaijr/EAMamba


<a name="SR"></a>

# è¶…åˆ†è¾¨ç‡(Super-Resolution)




<a name="Denoising"></a>

# å»å™ª(Denoising)

## å›¾åƒå»å™ª(Image Denoising)

<a name="3D-Human-Pose-Estimation"></a>

# 3Däººä½“å§¿æ€ä¼°è®¡(3D Human Pose Estimation)



<a name="3DVG"></a>

#3D Visual Grounding(3Dè§†è§‰å®šä½)




<a name="Image-Generation"></a>

# å›¾åƒç”Ÿæˆ(Image Generation)

**DreamRenderer: Taming Multi-Instance Attribute Control in Large-Scale Text-to-Image Models**

- Paper: https://github.com/limuloo/DreamRenderer
- Code: https://arxiv.org/abs/2503.12885

**LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing**
- Paper: https://arxiv.org/abs/2507.22627
- Code: 
- Home: https://intelligolabs.github.io/lots/


<a name="Video-Generation"></a>

# è§†é¢‘ç”Ÿæˆ(Video Generation)




<a name="Image-Editing"></a>

# å›¾åƒç¼–è¾‘(Image Editing)

**Rethinking the Spatial and Temporal Redundancy for Efficient Image Editing**

- Project: https://eff-edit.github.io
- Paper: https://arxiv.org/abs/2503.10270
- Code: https://github.com/yuriYanZeXuan/EEdit



<a name="Video-Editing"></a>

# è§†é¢‘ç¼–è¾‘(Video Editing)



<a name="3D-Generation"></a>

# 3Dç”Ÿæˆ(3D Generation)





<a name="3D-Reconstruction"></a>

# 3Dé‡å»º(3D Reconstruction)





<a name="HMG"></a>

# äººä½“è¿åŠ¨ç”Ÿæˆ(Human Motion Generation)




<a name="Video-Understanding"></a>

# è§†é¢‘ç†è§£(Video Understanding)

**Vamba: Understanding Hour-Long Videos with Hybrid Mamba-Transformers**

- Projectï¼šhttps://tiger-ai-lab.github.io/Vamba/
- Paperï¼šhttps://arxiv.org/abs/2503.11579
- Codeï¼šhttps://github.com/TIGER-AI-Lab/Vamba


<a name="Embodied"></a>

# å…·èº«æ™ºèƒ½(Embodied AI)





<a name="KD"></a>

# çŸ¥è¯†è’¸é¦(Knowledge Distillation)

<a name="Depth-Estimation"></a>


# æ·±åº¦ä¼°è®¡(Depth Estimation)





<a name="Stereo-Matching"></a>

# ç«‹ä½“åŒ¹é…(Stereo Matching)





<a name="Low-light"></a>

# æš—å…‰å›¾åƒå¢å¼º(Low-light Image Enhancement)





<a name="IC"></a>

# å›¾åƒå‹ç¼©(Image Compression)](#IC)




<a name="SGG"></a>

# åœºæ™¯å›¾ç”Ÿæˆ(Scene Graph Generation)



<a name="ST"></a>

# é£æ ¼è¿ç§»(Style Transfer)


<a name="SGG"></a>
#  åœºæ™¯å›¾ç”Ÿæˆ(Scene Graph Generation)
- Paper: https://arxiv.org/abs/2505.18151
- Code: 
- Home: https://kyleleey.github.io/WonderPlay/



<a name="IQA"></a>

# å›¾åƒè´¨é‡è¯„ä»·(Image Quality Assessment)




<a name="Video-Quality-Assessment"></a>

# è§†é¢‘è´¨é‡è¯„ä»·(Video Quality Assessment)

<a name="CS"></a>

# å‹ç¼©æ„ŸçŸ¥(Compressive Sensing)



<a name="Datasets"></a>

# æ•°æ®é›†(Datasets)


**ROADWork Dataset: Learning to Recognize, Observe, Analyze and Drive Through Work Zones**

- Paper: https://arxiv.org/abs/2406.07661
- Code: https://github.com/anuragxel/roadwork-dataset
- Project: https://www.cs.cmu.edu/~ILIM/roadwork_dataset/




<a name="Others"></a>

# å…¶ä»–(Others)

**Music Grounding by Short Video**

- Project: https://rucmm.github.io/VMMR/
- Paper: https://arxiv.org/abs/2408.16990
- Code link: https://github.com/xxayt/MGSV



